{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Bogotaâ€™s TransMilenio Bus Rapid Transit system, which opened in 2000, is one of the largest and most heavily used in the world. The system which handles passengers in excess of 2.4 million every day provides transportation for about 69% of the population of Bogota\n",
    "\n",
    "This project's objective is to extract a point in time ridership information covering the BRT's over 190 stations, transform and load this information into a Postgres Database to allow for easy querying and analysis of the complete data.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset is in the format of fixed width text files. Each text file may have repeating headers in the body of the files. Each file is stored by date in a month folder with th folder itself being stored in a phase I or phase II folder. The sample data is shown below. Some files had extra columns included in the data. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CODIGOESTACION                         NUMEROMOLINETE                         FECHAINICIAL        FECHAFINAL          S   CANTIDAD\n",
    "-------------------------------------- -------------------------------------- ------------------- ------------------- - ----------\n",
    "12000                                  1211201                                01-04-2010 04:00:00 01-04-2010 04:14:59 S          1\n",
    "12000                                  1211201                                01-04-2010 05:45:00 01-04-2010 05:59:59 E          3\n",
    "12000                                  1211201                                01-04-2010 06:00:00 01-04-2010 06:14:59 E          3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution.\n",
    "The pandas module was used heavily to import the Fixed width Files, remove unneeded columns, and prep the files before loading into a Postgres database using sqlalchemy. Due to unknown issues with jupyter notobook, the complete execution was run directly in windows cmd prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob            # use glob module to specify base directory and file extensions to grab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "t0 = time.clock()\n",
    "\n",
    "file_list = glob.glob(\"E:/Bogota_BRT_project_data/data/***/**/*.txt\")\n",
    "\n",
    "\n",
    "# READ AND TRANSFORM FILES WITHIN THIS FOR-LOOP\n",
    "\n",
    "# Empty list to hold processed files\n",
    "frames = []\n",
    "\n",
    "# Keep count of processed files  \n",
    "count = 1\n",
    "\n",
    "for file in file_list:\n",
    "     \n",
    "    with open(file) as f:\n",
    "        line = f.readline()\n",
    "        while line.isspace():\n",
    "            line = f.readline()\n",
    "            break\n",
    "        header = line.lower().strip().split()\n",
    "\n",
    "    # Transform headers. Some file headers have 'sum(cantidad)' instead of 'cantidad', change all to cantidad\n",
    "    if 'sum(cantidad)' in header:\n",
    "        header = ['cantidad' if x == 'sum(cantidad)' else x for x in header]\n",
    "\n",
    "\n",
    "    # read fixed width file\n",
    "    df = pd.read_fwf(file, header =0, names=header)\n",
    "\n",
    "    # test for repeating headers and the '---' character.Header text is capitalized. \n",
    "    a = df.loc[df['s'] == '-']\n",
    "\n",
    "    b = df.loc[df['codigoestacion'] == 'CODIGOESTACION']\n",
    "\n",
    "    # grab their indeces to delete rows\n",
    "    row_to_clean1 = list(a.index)\n",
    "\n",
    "    row_to_clean2 = list(b.index)\n",
    "\n",
    "\n",
    "    # drop rows using indexes\n",
    "    df.drop(row_to_clean1, axis = 0, inplace=True)\n",
    "\n",
    "    df.drop(row_to_clean2, axis = 0, inplace=True)\n",
    "\n",
    "    # Get a list of cols from dataframe and delete cols 'IDARTIFICIALTARIFA' and 'DESCRIPCION' if they exist\n",
    "    if 'idartificialtarifa' and 'descripcion' in df.columns:\n",
    "        df.drop(['idartificialtarifa', 'descripcion'], axis = 1, inplace=True)\n",
    "    \n",
    "    # Convert dates from d-m-y to y-m-d...this is ISO 8601 standard. Will prevent problems when exporting to postgres\n",
    "    cols = ['fechafinal','fechainicial']\n",
    "\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_datetime(df[col], dayfirst = True)\n",
    "    \n",
    "    # append dataframes to the list object frames.\n",
    "    frames.append(df)\n",
    "\n",
    "    print(\" {}: {}: processed\".format(count, file))\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# Join all dataframes in the frames list object together along the rows (axis = 0)    \n",
    "DF = pd.concat(frames, ignore_index = True)\n",
    "\n",
    "# Access dframe index and set it to start from 1. Set the index name to 'id'\n",
    "DF.index = np.arange(1, len(DF)+1)\n",
    "DF.index.name = 'id'\n",
    "\n",
    "t1 = time.clock()\n",
    "\n",
    "print(\"Total number of files processed: {}\".format(count))\n",
    "print(\"Time to execute in minutes: {}\".format((t1-t0)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Export to PostgreSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy  # Package for accessing SQL databases via Python\n",
    "import psycopg2\n",
    "from sqlalchemy.types import String, Integer, DateTime # use to define dataypes in the db\n",
    "\n",
    "t2 = time.clock()\n",
    "\n",
    "# Create connection engine - format: \"databasedialect://user:password@host/database\"\n",
    "engine = sqlalchemy.create_engine(\"postgresql://postgres:12345@localhost/bogota_metro_production\")\n",
    "con = engine.connect()\n",
    "\n",
    "# Verify if any tables exist in the database' \n",
    "print(engine.table_names())\n",
    "\n",
    "# Specify tablename in postgres Dbase\n",
    "table_name = 'bogota_metro'\n",
    "\n",
    "# Write dataframe to Postgres in chunks\n",
    "try:\n",
    "    DF.to_sql(table_name, con, if_exists = \"replace\",chunksize= 10000, index = True, \n",
    "              dtype={'codigoestacion': Integer, 'numeromolinete': Integer,\n",
    "                     'fechainicial':DateTime,'fechafinal':DateTime,'s':String,'cantidad':Integer})    \n",
    "except ValueError as vx:\n",
    "    print(vx)\n",
    "except Exception as ex:   \n",
    "    print(ex)\n",
    "else:\n",
    "    print(\"Postgres Table {} has been successfully created\".format(table_name) )\n",
    "finally:\n",
    "    con.close()\n",
    "    \n",
    "t3 = time.clock()\n",
    "print(\"Time to load 88 Million rows from dataframe to Postgres: {}\".format((t3-t2)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![title](Capture.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a simple query on database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>codigoestacion</th>\n",
       "      <th>numeromolinete</th>\n",
       "      <th>fechainicial</th>\n",
       "      <th>fechafinal</th>\n",
       "      <th>s</th>\n",
       "      <th>cantidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88217298</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 23:15:00</td>\n",
       "      <td>2010-09-30 23:29:59</td>\n",
       "      <td>E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88217297</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:45:00</td>\n",
       "      <td>2010-09-30 22:59:59</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88217296</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:30:00</td>\n",
       "      <td>2010-09-30 22:44:59</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88217295</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:30:00</td>\n",
       "      <td>2010-09-30 22:44:59</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88217294</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:15:00</td>\n",
       "      <td>2010-09-30 22:29:59</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88217293</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:15:00</td>\n",
       "      <td>2010-09-30 22:29:59</td>\n",
       "      <td>E</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88217292</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 22:00:00</td>\n",
       "      <td>2010-09-30 22:14:59</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88217291</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 21:45:00</td>\n",
       "      <td>2010-09-30 21:59:59</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88217290</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 21:30:00</td>\n",
       "      <td>2010-09-30 21:44:59</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>88217289</td>\n",
       "      <td>7113</td>\n",
       "      <td>1111401</td>\n",
       "      <td>2010-09-30 21:30:00</td>\n",
       "      <td>2010-09-30 21:44:59</td>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  codigoestacion  numeromolinete        fechainicial  \\\n",
       "0  88217298            7113         1111401 2010-09-30 23:15:00   \n",
       "1  88217297            7113         1111401 2010-09-30 22:45:00   \n",
       "2  88217296            7113         1111401 2010-09-30 22:30:00   \n",
       "3  88217295            7113         1111401 2010-09-30 22:30:00   \n",
       "4  88217294            7113         1111401 2010-09-30 22:15:00   \n",
       "5  88217293            7113         1111401 2010-09-30 22:15:00   \n",
       "6  88217292            7113         1111401 2010-09-30 22:00:00   \n",
       "7  88217291            7113         1111401 2010-09-30 21:45:00   \n",
       "8  88217290            7113         1111401 2010-09-30 21:30:00   \n",
       "9  88217289            7113         1111401 2010-09-30 21:30:00   \n",
       "\n",
       "           fechafinal  s  cantidad  \n",
       "0 2010-09-30 23:29:59  E         2  \n",
       "1 2010-09-30 22:59:59  S         1  \n",
       "2 2010-09-30 22:44:59  S         9  \n",
       "3 2010-09-30 22:44:59  E         1  \n",
       "4 2010-09-30 22:29:59  S         1  \n",
       "5 2010-09-30 22:29:59  E         3  \n",
       "6 2010-09-30 22:14:59  S         9  \n",
       "7 2010-09-30 21:59:59  S         6  \n",
       "8 2010-09-30 21:44:59  S         4  \n",
       "9 2010-09-30 21:44:59  E         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = engine.connect()\n",
    "# create a cursor obj using the connection\n",
    "#cur = con.cursor()\n",
    "query = '''select *  \n",
    "           from bogota_metro\n",
    "           order by id desc\n",
    "           limit 10;'''\n",
    "\n",
    "sql_df = pd.read_sql_query(query, con)\n",
    "\n",
    "sql_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table shows up with 88.2 Million plus rows with fechainicial and fechafinal datetime columns transformed from D-M-Y to Y-M-D ISO 8601 compliant.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
